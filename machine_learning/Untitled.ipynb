{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c75a4413-554d-4372-bdc9-6493d2355648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6323f138-5d87-4126-961f-476cdf9e115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e93a945-af70-4586-aa75-28b12d4549d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Filter to \"worst\" features only\n",
    "worst_columns = [col for col in df.columns if \"worst\" in col]\n",
    "X = df[worst_columns]\n",
    "y = df[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "535974f6-a1c8-4151-87c7-4d6f207d64b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d554f9-aad6-41ca-984e-fcccf0dc2d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Accuracy: 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "\n",
      "SVM (RBF) Accuracy: 0.96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        43\n",
      "           1       0.97      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "\n",
      "Decision Tree Accuracy: 0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        43\n",
      "           1       0.96      0.94      0.95        71\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.93      0.94      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "\n",
      "Random Forest Accuracy: 0.96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "\n",
      "XGBoost Accuracy: 0.96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        43\n",
      "           1       0.97      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:29:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "    \"SVM (RBF)\": SVC(kernel=\"rbf\", probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# Train models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    print(f\"\\n{name} Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca1c4f7d-249b-4bfb-a97e-c9d8edeb40a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Best RF Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "RF Best CV Score: 0.9604395604395604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Store best models\n",
    "best_models = {}\n",
    "\n",
    "# 1Ô∏è‚É£ Random Forest Grid Search\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train_scaled, y_train)\n",
    "best_models['Random Forest'] = rf_grid.best_estimator_\n",
    "print(\"\\nüîç Best RF Parameters:\", rf_grid.best_params_)\n",
    "print(\"RF Best CV Score:\", rf_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be9fe52f-899b-42ea-8f44-e4c904bc1a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Best SVM Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVM Best CV Score: 0.9714285714285713\n"
     ]
    }
   ],
   "source": [
    "# 2Ô∏è‚É£ SVM Grid Search\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm_grid = GridSearchCV(SVC(probability=True), svm_params, cv=5, scoring='accuracy')\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "best_models['SVM'] = svm_grid.best_estimator_\n",
    "print(\"\\nüîç Best SVM Parameters:\", svm_grid.best_params_)\n",
    "print(\"SVM Best CV Score:\", svm_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b02749c7-6c08-480a-a058-d39b97aa665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Best XGBoost Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "XGBoost Best CV Score: 0.956043956043956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/vscode/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# 3Ô∏è‚É£ XGBoost Grid Search\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    xgb_params,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "xgb_grid.fit(X_train_scaled, y_train)\n",
    "best_models['XGBoost'] = xgb_grid.best_estimator_\n",
    "print(\"\\nüîç Best XGBoost Parameters:\", xgb_grid.best_params_)\n",
    "print(\"XGBoost Best CV Score:\", xgb_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eb9738d-ab67-4a90-829f-63d355bac206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.9604</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.9714</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.956</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Best Score                                        Best Params\n",
       "Random Forest     0.9604  {'max_depth': None, 'min_samples_split': 5, 'n...\n",
       "SVM               0.9714   {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
       "XGBoost            0.956  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary of best models and scores\n",
    "summary = pd.DataFrame({\n",
    "    model: {\n",
    "        'Best Score': round(grid.best_score_, 4),\n",
    "        'Best Params': grid.best_params_\n",
    "    }\n",
    "    for model, grid in zip(['Random Forest', 'SVM', 'XGBoost'], [rf_grid, svm_grid, xgb_grid])\n",
    "}).T\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6be27b9e-5897-42cc-8f69-4746c9b5f762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: shap in /home/vscode/.local/lib/python3.13/site-packages (0.48.0)\n",
      "Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.13/site-packages (from shap) (2.2.0)\n",
      "Requirement already satisfied: scipy in /home/vscode/.local/lib/python3.13/site-packages (from shap) (1.16.1)\n",
      "Requirement already satisfied: scikit-learn in /home/vscode/.local/lib/python3.13/site-packages (from shap) (1.7.1)\n",
      "Requirement already satisfied: pandas in /home/vscode/.local/lib/python3.13/site-packages (from shap) (2.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /opt/conda/lib/python3.13/site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in /opt/conda/lib/python3.13/site-packages (from shap) (24.2)\n",
      "Requirement already satisfied: slicer==0.0.8 in /home/vscode/.local/lib/python3.13/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in /home/vscode/.local/lib/python3.13/site-packages (from shap) (0.61.2)\n",
      "Requirement already satisfied: cloudpickle in /home/vscode/.local/lib/python3.13/site-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.13/site-packages (from shap) (4.12.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/vscode/.local/lib/python3.13/site-packages (from numba>=0.54->shap) (0.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.13/site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.13/site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vscode/.local/lib/python3.13/site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/vscode/.local/lib/python3.13/site-packages (from scikit-learn->shap) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/vscode/.local/lib/python3.13/site-packages (from scikit-learn->shap) (3.6.0)\n",
      "Found existing installation: numpy 2.2.0\n",
      "Uninstalling numpy-2.2.0:\n",
      "  Successfully uninstalled numpy-2.2.0\n",
      "\u001b[33mWARNING: Skipping numpy as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting numpy==2.2\n",
      "  Using cached numpy-2.2.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Using cached numpy-2.2.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.2.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numba in /home/vscode/.local/lib/python3.13/site-packages (0.61.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/vscode/.local/lib/python3.13/site-packages (from numba) (0.44.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.24 in /home/vscode/.local/lib/python3.13/site-packages (from numba) (2.2.0)\n",
      "2.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install shap \n",
    "!pip uninstall -y numpy\n",
    "!python3.13 -m pip uninstall -y numpy\n",
    "!pip install --user numpy==2.2\n",
    "!pip install numba\n",
    "\n",
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b653b14-c37d-4876-9715-42c4fd33f95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 2.2 or less. Got NumPy 2.3.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(np.__version__)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshap\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Use TreeExplainer for tree-based models\u001b[39;00m\n\u001b[32m      6\u001b[39m shap.initjs()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/shap/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_explanation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Cohorts, Explanation\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# explainers\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexplainers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m other\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/shap/_explanation.py:16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mslicer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Alias, Obj, Slicer\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_clustering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hclust_ordering\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_exceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DimensionError\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_general\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpChain\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/shap/utils/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_clustering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     delta_minimization_order,\n\u001b[32m      3\u001b[39m     hclust,\n\u001b[32m      4\u001b[39m     hclust_ordering,\n\u001b[32m      5\u001b[39m     partition_tree,\n\u001b[32m      6\u001b[39m     partition_tree_shuffle,\n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_general\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     OpChain,\n\u001b[32m     10\u001b[39m     approximate_interactions,\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     suppress_stderr,\n\u001b[32m     21\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_masked_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MaskedModel, make_masks\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/shap/utils/_clustering.py:12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspatial\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m njit\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_exceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DimensionError\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_show_progress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_progress\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/numba/__init__.py:59\u001b[39m\n\u001b[32m     54\u001b[39m             msg = (\u001b[33m\"\u001b[39m\u001b[33mNumba requires SciPy version 1.0 or greater. Got SciPy \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     55\u001b[39m                    \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscipy.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43m_ensure_critical_deps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# END DO NOT MOVE\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# ---------------------- WARNING WARNING WARNING ----------------------------\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_versions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/numba/__init__.py:45\u001b[39m, in \u001b[36m_ensure_critical_deps\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m numpy_version > (\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m):\n\u001b[32m     43\u001b[39m     msg = (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumba needs NumPy 2.2 or less. Got NumPy \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     44\u001b[39m            \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_version[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_version[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Numba needs NumPy 2.2 or less. Got NumPy 2.3."
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "import shap\n",
    "\n",
    "\n",
    "# Use TreeExplainer for tree-based models\n",
    "shap.initjs()\n",
    "\n",
    "# Pick best model from tuning step (e.g., XGBoost)\n",
    "model = best_models[\"XGBoost\"]\n",
    "\n",
    "# Refit on full training set if needed\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# SHAP Explainer\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e94e6-97d4-4b4e-88c5-e855f9d14700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot (feature importance across all test samples)\n",
    "shap.summary_plot(shap_values, features=X_test, feature_names=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2e36e-b86e-44ae-836f-6335a12b3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain a single prediction\n",
    "i = 0  # change index to see other examples\n",
    "shap.plots.waterfall(shap_values[i], max_display=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67ce4a-fc37-4d94-afd6-7be7135d6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force plot (interactive)\n",
    "shap.plots.force(shap_values[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908964fc-0056-459a-94e8-f83a84d9a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "# Use best SVM model from tuning step\n",
    "svm_model = best_models['SVM']\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Create LIME explainer\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X_train_scaled,\n",
    "    feature_names=X.columns.tolist(),\n",
    "    class_names=['benign', 'malignant'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Explain a prediction\n",
    "i = 5  # index of test instance to explain\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=X_test_scaled[i],\n",
    "    predict_fn=svm_model.predict_proba,\n",
    "    num_features=10\n",
    ")\n",
    "\n",
    "# Show explanation\n",
    "exp.show_in_notebook(show_table=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d215f7b-d040-4ee3-a097-a736209119b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.save_to_file('lime_explanation.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca5b4e-4986-4b45-b658-4916e2933175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Example: Label Encoding (for binary columns)\n",
    "def label_encode(df, columns):\n",
    "    encoder = LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = encoder.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "# Example: One-Hot Encoding (for nominal categories)\n",
    "def one_hot_encode(df, columns):\n",
    "    return pd.get_dummies(df, columns=columns, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d8fe3c-1300-4437-89ef-4edcb895a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (if you had any object columns)\n",
    "cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "if cat_cols:\n",
    "    df = one_hot_encode(df, cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd46621-f169-4e42-b142-48cdfb8159f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
